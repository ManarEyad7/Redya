Metadata-Version: 2.1
Name: Ashaar
Version: 0.0.2
Summary: Arabic poetry analysis and generation library
Home-page: https://github.com/ARBML/Ashaar
Author-email: arabicmachinelearning@gmail.com
License: MIT
Requires-Python: >=3.9
Description-Content-Type: text/markdown

## Ashaar

[![Huggingface Space](https://img.shields.io/badge/ًں¤—-Demo%20-yellow.svg)](https://huggingface.co/spaces/arbml/Ashaar)
[![Colab Notebook](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Z6c0ogy8Yt89UJgT_fAvb0xdKwfBYxK_?usp=sharing)
[![GitHub](https://img.shields.io/badge/ًں’»-GitHub%20-black.svg)](https://github.com/ARBML/Ashaar)

Arabic poetry analysis and generation. 

<p align = 'center'>
<img src='https://raw.githubusercontent.com/ARBML/Ashaar/master/images/ashaar_icon.png' width='150px' alt='logo for Ashaar'/>
</p>

## Installation

```
pip install .
```

## Generation 

### Training 

Training the character based gpt-2 model. Our model was trained on A100 for around 500k steps. 

```
python run_clm.py \
        --model_type gpt2 \
        --config_overrides="n_layer=10,vocab_size=100" \
        --dataset_name arbml/Ashaar_dataset \
        --tokenizer_name arbml/ashaar_tokenizer \
        --per_device_train_batch_size 16 \
        --per_device_eval_batch_size 4 \
        --do_train \
        --do_eval \
        --num_train_epochs=100 \
        --eval_steps=500 \
        --logging_steps=1 \
        --save_steps=500 \
        --logging_strategy='steps' \
        --evaluation_strategy='steps' \
        --save_strategy='steps' \
        --output_dir <output-dir> \
        --report_to="wandb" \
        --overwrite_output_dir \
        --push_to_hub \
        --hub_model_id=<model-hub-id>
```

### Inference 

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

prompt = "enter your prompt here"
gpt_tokenizer = AutoTokenizer.from_pretrained('arbml/Ashaar_tokenizer')
model = AutoModelForCausalLM.from_pretrained('arbml/Ashaar_model')

encoded_input = gpt_tokenizer(prompt, return_tensors='pt')
output = model.generate(**encoded_input, max_length = 512, top_p = 3, do_sample=True)
```

## Analysis

```python
from Ashaar.bait_analysis import BaitAnalysis

prompt ="ط£ظ„ط§ ظ„ظٹطھ ط´ط¹ط±ظٹ ظ‡ظ„ ط£ط¨ظٹطھظ† ظ„ظٹظ„ط© # ط¨ط¬ظ†ط¨ ط§ظ„ط؛ط¶ظ‰ ط£ط²ط¬ظٹ ط§ظ„ظ‚ظ„ط§طµ ط§ظ„ظ†ظˆط§ط¬ظٹط§"
analysis = BaitAnalysis()
output = analysis.analyze(prompt, override_tashkeel=True)
```

Sample output 

```
{'diacritized': ['ط£ظژظ„ط§ ظ„ظژظٹظ’طھظژ ط´ظگط¹ظ’ط±ظگظٹ ظ‡ظژظ„ظ’ ط£ظژط¨ظژظٹظ’طھظژظ†ظژظ‘ ظ„ظژظٹظ’ظ„ظژط©ظ‹ # ط¨ظگط¬ظژظ†ظ’ط¨ظگ ط§ظ„ظ’ط؛ظژط¶ظژظ‰ ط£ظژط²ظڈط¬ظژظٹظژظ‘ ط§ظ„ظ’ظ‚ظژظ„ظژط§طµظگ ط§ظ„ظ†ظژظ‘ظˆظژط§ط¬ظگظٹظژط§'],
 'arudi_style': [('ط£ظ„ط§ ظ„ظٹطھ ط´ط¹ط±ظٹ ظ‡ظ„ ط£ط¨ظٹطھظ†ظ† ظ„ظٹظ„طھظ†', '10110110101011010110110'),
  ('ط¨ط¬ظ†ط¨ ظ„ط؛ط¶ظ‰ ط£ط²ط¬ظٹظٹ ظ„ظ‚ظ„ط§طµ ظ†ظ†ظˆط§ط¬ظٹط§', '1101011011101011010110110')],
 'patterns_mismatches': ['G1G0R1G1G0G1G1G0G1G0G1G0G1G1G0G1G0G1G1G0G1G1G0',
  'G1G1G0G1G0G1G1G0R1R1G1G0G1G0G1G1G0G1G0G1G1G0G1G1G0'],
 'qafiyah': ('ظٹ',
  'ظ‚ط§ظپظٹط© ط¨ط­ط±ظپ ط§ظ„ط±ظˆظٹ: ظٹ طŒ  ط²ط§ط¯ ظ„ظ‡ط§ ط§ظ„ظˆطµظ„ ط¨ط¥ط´ط¨ط§ط¹ ط±ظˆظٹظ‡ط§ ط²ط§ط¯ ظ„ظ‡ط§ ط§ظ„طھط£ط³ظٹط³'),
 'meter': 'ط§ظ„ط·ظˆظٹظ„',
 'closest_baits': [[('ظپظژظٹظژط§ ظ„ظژظٹظ’طھظژظ†ظگظٹ ظ„ظژظ…ظ’ ط£ظژط¹ظ’ظ†ظگ ط¨ظگط§ظ„ظ’ظ…ظڈظ„ظ’ظƒظگ ط³ظژط§ط¹ظژط©ظ‹ # ظˆظژظ„ظژظ…ظ’ ط£ظژظ„ظ’ظ‡ظڈ ظپظگظٹ ظ„ظژط°ظژظ‘ط§طھظگ ط¹ظژظٹظ’ط´ظچ ظ†ظژظˆظژط§ط¶ظگط±ظگ',
    [0.8884615898132324])]],
 'era': ['ط§ظ„ط¹طµط± ط§ظ„ط¬ط§ظ‡ظ„ظٹ', 'ط§ظ„ط¹طµط± ط§ظ„ط¥ط³ظ„ط§ظ…ظٹ', 'ط§ظ„ط¹طµط± ط§ظ„ط£ظ…ظˆظٹ', 'ظ‚ط¨ظ„ ط§ظ„ط¥ط³ظ„ط§ظ…'],
 'closest_patterns': [('1010110101011010110110',
   0.9777777777777777,
   'ط¹ظˆظ„ظ†ظ’ ظ…ظپط§ط¹ظٹظ„ظ†ظ’ ظپط¹ظˆظ„ظ†ظ’ ظ…ظپط§ط¹ظ„ظ†ظ’'),
  ('11010110101011010110110',
   0.9583333333333334,
   'ظپط¹ظˆظ„ظ†ظ’ ظ…ظپط§ط¹ظٹظ„ظ†ظ’ ظپط¹ظˆظ„ظ†ظ’ ظ…ظپط§ط¹ظ„ظ†ظ’')],
 'theme': ['ظ‚طµظٹط¯ط© ط±ظˆظ…ظ†ط³ظٹظ‡', 'ظ‚طµظٹط¯ط© ط´ظˆظ‚', 'ظ‚طµظٹط¯ط© ط؛ط²ظ„']}
```

## Citation 
```
@article{alyafeai2023ashaar,
  title={Ashaar: Automatic Analysis and Generation of Arabic Poetry Using Deep Learning Approaches},
  author={Alyafeai, Zaid and Al-Shaibani, Maged S and Ahmed, Moataz},
  journal={arXiv preprint arXiv:2307.06218},
  year={2023}
}
```
